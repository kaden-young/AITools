{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.svm import SVR\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in the 100k feather file\n",
    "df = pd.read_feather('100k_kindle_reviews.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[39mreturn\u001b[39;00m lemmatized_text\n\u001b[0;32m     13\u001b[0m \u001b[39m# Apply the preprocessing function to the 'reviewText' column\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mprocessed_review\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39;49m\u001b[39mreviewText\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(preprocess_text)\n",
      "File \u001b[1;32mc:\\Users\\youngkj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4661\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4662\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4666\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4667\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   4668\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4669\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4670\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4769\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4770\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4771\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[1;32mc:\\Users\\youngkj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:1105\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1102\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m   1104\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1105\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\youngkj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:1156\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1154\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1155\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[1;32m-> 1156\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[0;32m   1157\u001b[0m             values,\n\u001b[0;32m   1158\u001b[0m             f,\n\u001b[0;32m   1159\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[0;32m   1160\u001b[0m         )\n\u001b[0;32m   1162\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1163\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1164\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1165\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\youngkj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\lib.pyx:2918\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[3], line 9\u001b[0m, in \u001b[0;36mpreprocess_text\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpreprocess_text\u001b[39m(text):\n\u001b[1;32m----> 9\u001b[0m     doc \u001b[39m=\u001b[39m nlp(text)\n\u001b[0;32m     10\u001b[0m     lemmatized_text \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([token\u001b[39m.\u001b[39mlemma_ \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m doc \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m token\u001b[39m.\u001b[39mis_stop])\n\u001b[0;32m     11\u001b[0m     \u001b[39mreturn\u001b[39;00m lemmatized_text\n",
      "File \u001b[1;32mc:\\Users\\youngkj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\language.py:1026\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m   1024\u001b[0m     error_handler \u001b[39m=\u001b[39m proc\u001b[39m.\u001b[39mget_error_handler()\n\u001b[0;32m   1025\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1026\u001b[0m     doc \u001b[39m=\u001b[39m proc(doc, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcomponent_cfg\u001b[39m.\u001b[39;49mget(name, {}))  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m   1027\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1028\u001b[0m     \u001b[39m# This typically happens if a component is not initialized\u001b[39;00m\n\u001b[0;32m   1029\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE109\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\youngkj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\pipeline\\attributeruler.py:143\u001b[0m, in \u001b[0;36mAttributeRuler.__call__\u001b[1;34m(self, doc)\u001b[0m\n\u001b[0;32m    141\u001b[0m error_handler \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_error_handler()\n\u001b[0;32m    142\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 143\u001b[0m     matches \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmatch(doc)\n\u001b[0;32m    144\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_annotations(doc, matches)\n\u001b[0;32m    145\u001b[0m     \u001b[39mreturn\u001b[39;00m doc\n",
      "File \u001b[1;32mc:\\Users\\youngkj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\pipeline\\attributeruler.py:152\u001b[0m, in \u001b[0;36mAttributeRuler.match\u001b[1;34m(self, doc)\u001b[0m\n\u001b[0;32m    150\u001b[0m matches \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmatcher(doc, allow_missing\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, as_spans\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    151\u001b[0m \u001b[39m# Sort by the attribute ID, so that later rules have precedence\u001b[39;00m\n\u001b[1;32m--> 152\u001b[0m matches \u001b[39m=\u001b[39m [\n\u001b[0;32m    153\u001b[0m     (\u001b[39mint\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvocab\u001b[39m.\u001b[39;49mstrings[m_id]), m_id, s, e) \u001b[39mfor\u001b[39;49;00m m_id, s, e \u001b[39min\u001b[39;49;00m matches  \u001b[39m# type: ignore\u001b[39;49;00m\n\u001b[0;32m    154\u001b[0m ]\n\u001b[0;32m    155\u001b[0m matches\u001b[39m.\u001b[39msort()\n\u001b[0;32m    156\u001b[0m \u001b[39mreturn\u001b[39;00m matches\n",
      "File \u001b[1;32mc:\\Users\\youngkj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\pipeline\\attributeruler.py:152\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    150\u001b[0m matches \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmatcher(doc, allow_missing\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, as_spans\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    151\u001b[0m \u001b[39m# Sort by the attribute ID, so that later rules have precedence\u001b[39;00m\n\u001b[1;32m--> 152\u001b[0m matches \u001b[39m=\u001b[39m [\n\u001b[0;32m    153\u001b[0m     (\u001b[39mint\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocab\u001b[39m.\u001b[39mstrings[m_id]), m_id, s, e) \u001b[39mfor\u001b[39;00m m_id, s, e \u001b[39min\u001b[39;00m matches  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[0;32m    154\u001b[0m ]\n\u001b[0;32m    155\u001b[0m matches\u001b[39m.\u001b[39msort()\n\u001b[0;32m    156\u001b[0m \u001b[39mreturn\u001b[39;00m matches\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load the Spacy language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Function to perform lemmatization and stop word removal\n",
    "def preprocess_text(text):\n",
    "    doc = nlp(text)\n",
    "    lemmatized_text = ' '.join([token.lemma_ for token in doc if not token.is_stop])\n",
    "    return lemmatized_text\n",
    "\n",
    "# Apply the preprocessing function to the 'reviewText' column\n",
    "df['processed_review'] = df['reviewText'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit CountVectorizer to learn the vocabulary (word dictionary)\n",
    "vectorizer.fit(df['processed_review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_components_range = range(1, 200, 10)  # Define the range of components to test\n",
    "# explained_variance = []\n",
    "\n",
    "# for n_components in n_components_range:\n",
    "#     svd = TruncatedSVD(n_components=n_components)\n",
    "#     svd.fit(vectorizer.transform(df['processed_review']))\n",
    "#     explained_variance.append(svd.explained_variance_ratio_.sum())\n",
    "\n",
    "# # Plot the explained variance ratio to identify the elbow point\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(n_components_range, explained_variance, marker='o', linestyle='-')\n",
    "# plt.xlabel('Number of Components')\n",
    "# plt.ylabel('Explained Variance Ratio')\n",
    "# plt.title('Elbow Method for Optimal Number of Components')\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in M6 Pitch\\100k_kindle_reviews.feather\n",
    "df = pd.read_feather('100k_kindle_reviews_lemmatized.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>style</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>vote</th>\n",
       "      <th>image</th>\n",
       "      <th>processed_review</th>\n",
       "      <th>lemmatized_text</th>\n",
       "      <th>ADV</th>\n",
       "      <th>VERB</th>\n",
       "      <th>PRON</th>\n",
       "      <th>SCONJ</th>\n",
       "      <th>DET</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>ADP</th>\n",
       "      <th>CCONJ</th>\n",
       "      <th>PUNCT</th>\n",
       "      <th>AUX</th>\n",
       "      <th>PART</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>NUM</th>\n",
       "      <th>SPACE</th>\n",
       "      <th>INTJ</th>\n",
       "      <th>SYM</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12 27, 2014</td>\n",
       "      <td>A3JRP9RI3ZE6VK</td>\n",
       "      <td>B00JQDHIES</td>\n",
       "      <td>{'Format:': ' Kindle Edition'}</td>\n",
       "      <td>e-BOOK</td>\n",
       "      <td>Truly hate it when I make a bad call on a book...</td>\n",
       "      <td>Juvenile</td>\n",
       "      <td>1419638400</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>truly hate bad book waste money . honestly fin...</td>\n",
       "      <td>truly hate bad book waste money . honestly fin...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>06 25, 2016</td>\n",
       "      <td>A3IZWB0YUZXZZ6</td>\n",
       "      <td>B01H124NQQ</td>\n",
       "      <td>{'Format:': ' Kindle Edition'}</td>\n",
       "      <td>Kathryn childs</td>\n",
       "      <td>Only 4% of this book is the discretion it isn'...</td>\n",
       "      <td>Not worth your time</td>\n",
       "      <td>1466812800</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>4 % book discretion worth time money . say 800...</td>\n",
       "      <td>4 % book discretion worth time money . say 800...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>05 13, 2013</td>\n",
       "      <td>A82LP6E48UFM5</td>\n",
       "      <td>B00C2E9EK4</td>\n",
       "      <td>{'Format:': ' Kindle Edition'}</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>The quality of writing for this book is very p...</td>\n",
       "      <td>poor quality</td>\n",
       "      <td>1368403200</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>quality writing book poor .   understand insta...</td>\n",
       "      <td>quality writing book poor .   understand insta...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>05 10, 2012</td>\n",
       "      <td>AMV9B31WKSLM7</td>\n",
       "      <td>B005RH2GNU</td>\n",
       "      <td>{'Format:': ' Kindle Edition'}</td>\n",
       "      <td>Eclectic Reader</td>\n",
       "      <td>The Outback is the vast, remote, arid area of ...</td>\n",
       "      <td>Outback is in AUSTRALIA!!!</td>\n",
       "      <td>1336608000</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>Outback vast , remote , arid area Australia ac...</td>\n",
       "      <td>Outback vast , remote , arid area Australia ac...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>09 4, 2013</td>\n",
       "      <td>AZ27B4OUL64TR</td>\n",
       "      <td>B00DC7PXLY</td>\n",
       "      <td>{'Format:': ' Kindle Edition'}</td>\n",
       "      <td>Word Junkie</td>\n",
       "      <td>Grace Burrowes lives within a few miles of me,...</td>\n",
       "      <td>Not as good as its progenitor</td>\n",
       "      <td>1378252800</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>Grace Burrowes live mile , want tell enjoy Gro...</td>\n",
       "      <td>Grace Burrowes live mile , want tell enjoy Gro...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall  verified   reviewTime      reviewerID        asin  \\\n",
       "0        1      True  12 27, 2014  A3JRP9RI3ZE6VK  B00JQDHIES   \n",
       "1        1     False  06 25, 2016  A3IZWB0YUZXZZ6  B01H124NQQ   \n",
       "2        1      True  05 13, 2013   A82LP6E48UFM5  B00C2E9EK4   \n",
       "3        1      True  05 10, 2012   AMV9B31WKSLM7  B005RH2GNU   \n",
       "4        1      True   09 4, 2013   AZ27B4OUL64TR  B00DC7PXLY   \n",
       "\n",
       "                            style     reviewerName  \\\n",
       "0  {'Format:': ' Kindle Edition'}           e-BOOK   \n",
       "1  {'Format:': ' Kindle Edition'}   Kathryn childs   \n",
       "2  {'Format:': ' Kindle Edition'}  Amazon Customer   \n",
       "3  {'Format:': ' Kindle Edition'}  Eclectic Reader   \n",
       "4  {'Format:': ' Kindle Edition'}      Word Junkie   \n",
       "\n",
       "                                          reviewText  \\\n",
       "0  Truly hate it when I make a bad call on a book...   \n",
       "1  Only 4% of this book is the discretion it isn'...   \n",
       "2  The quality of writing for this book is very p...   \n",
       "3  The Outback is the vast, remote, arid area of ...   \n",
       "4  Grace Burrowes lives within a few miles of me,...   \n",
       "\n",
       "                         summary  unixReviewTime  vote image  \\\n",
       "0                       Juvenile      1419638400     0  None   \n",
       "1            Not worth your time      1466812800     0  None   \n",
       "2                   poor quality      1368403200     0  None   \n",
       "3     Outback is in AUSTRALIA!!!      1336608000     0  None   \n",
       "4  Not as good as its progenitor      1378252800     0  None   \n",
       "\n",
       "                                    processed_review  \\\n",
       "0  truly hate bad book waste money . honestly fin...   \n",
       "1  4 % book discretion worth time money . say 800...   \n",
       "2  quality writing book poor .   understand insta...   \n",
       "3  Outback vast , remote , arid area Australia ac...   \n",
       "4  Grace Burrowes live mile , want tell enjoy Gro...   \n",
       "\n",
       "                                     lemmatized_text   ADV  VERB  PRON  SCONJ  \\\n",
       "0  truly hate bad book waste money . honestly fin...   4.0   5.0   3.0    2.0   \n",
       "1  4 % book discretion worth time money . say 800...   1.0   1.0   4.0    NaN   \n",
       "2  quality writing book poor .   understand insta...   6.0   8.0   7.0    1.0   \n",
       "3  Outback vast , remote , arid area Australia ac...   1.0   1.0   NaN    NaN   \n",
       "4  Grace Burrowes live mile , want tell enjoy Gro...  13.0  23.0  19.0    3.0   \n",
       "\n",
       "    DET   ADJ  NOUN   ADP  CCONJ  PUNCT   AUX  PART  PROPN  NUM  SPACE  INTJ  \\\n",
       "0   7.0   7.0   8.0   4.0    4.0    5.0   2.0   2.0    2.0  1.0    NaN   NaN   \n",
       "1   2.0   1.0   6.0   2.0    1.0    2.0   3.0   2.0    NaN  2.0    NaN   NaN   \n",
       "2  11.0   6.0  17.0   8.0    5.0    7.0   9.0   3.0    NaN  NaN    3.0   NaN   \n",
       "3   6.0   6.0   4.0   2.0    NaN    5.0   3.0   NaN    3.0  NaN    2.0   NaN   \n",
       "4  24.0  15.0  42.0  27.0   12.0   25.0  12.0  13.0   27.0  3.0    9.0   NaN   \n",
       "\n",
       "   SYM   X  \n",
       "0  NaN NaN  \n",
       "1  NaN NaN  \n",
       "2  NaN NaN  \n",
       "3  NaN NaN  \n",
       "4  NaN NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 71270)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming you already have your lemmatized text data in result_df['lemmatized_text']\n",
    "\n",
    "# Initialize CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit CountVectorizer to learn the vocabulary\n",
    "vectorizer.fit(df['lemmatized_text'])\n",
    "\n",
    "# Transform text data to numerical format\n",
    "X = vectorizer.transform(df['lemmatized_text'])\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 37.8 GiB for an array with shape (71270, 71279) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m svd \u001b[39m=\u001b[39m TruncatedSVD(n_components\u001b[39m=\u001b[39m\u001b[39mmin\u001b[39m(X\u001b[39m.\u001b[39mshape) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)  \u001b[39m# Set maximum number of components\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# Fit TruncatedSVD on the sparse matrix\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m svd\u001b[39m.\u001b[39;49mfit(X)\n\u001b[0;32m      6\u001b[0m \u001b[39m# Plotting the explained variance ratio\u001b[39;00m\n\u001b[0;32m      7\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m8\u001b[39m, \u001b[39m6\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\youngkj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\decomposition\\_truncated_svd.py:209\u001b[0m, in \u001b[0;36mTruncatedSVD.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    194\u001b[0m     \u001b[39m\"\"\"Fit model on training data X.\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \n\u001b[0;32m    196\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[39m        Returns the transformer object.\u001b[39;00m\n\u001b[0;32m    208\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 209\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_transform(X)\n\u001b[0;32m    210\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\youngkj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    156\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 157\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    158\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    159\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    160\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[0;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    162\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    163\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\youngkj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\youngkj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\decomposition\\_truncated_svd.py:246\u001b[0m, in \u001b[0;36mTruncatedSVD.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    241\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_components \u001b[39m>\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]:\n\u001b[0;32m    242\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    243\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mn_components(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_components\u001b[39m}\u001b[39;00m\u001b[39m) must be <=\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    244\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m n_features(\u001b[39m\u001b[39m{\u001b[39;00mX\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    245\u001b[0m         )\n\u001b[1;32m--> 246\u001b[0m     U, Sigma, VT \u001b[39m=\u001b[39m randomized_svd(\n\u001b[0;32m    247\u001b[0m         X,\n\u001b[0;32m    248\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_components,\n\u001b[0;32m    249\u001b[0m         n_iter\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_iter,\n\u001b[0;32m    250\u001b[0m         n_oversamples\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_oversamples,\n\u001b[0;32m    251\u001b[0m         power_iteration_normalizer\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpower_iteration_normalizer,\n\u001b[0;32m    252\u001b[0m         random_state\u001b[39m=\u001b[39;49mrandom_state,\n\u001b[0;32m    253\u001b[0m     )\n\u001b[0;32m    255\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcomponents_ \u001b[39m=\u001b[39m VT\n\u001b[0;32m    257\u001b[0m \u001b[39m# As a result of the SVD approximation error on X ~ U @ Sigma @ V.T,\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[39m# X @ V is not the same as U @ Sigma\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\youngkj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\extmath.py:449\u001b[0m, in \u001b[0;36mrandomized_svd\u001b[1;34m(M, n_components, n_oversamples, n_iter, power_iteration_normalizer, transpose, flip_sign, random_state, svd_lapack_driver)\u001b[0m\n\u001b[0;32m    445\u001b[0m \u001b[39mif\u001b[39;00m transpose:\n\u001b[0;32m    446\u001b[0m     \u001b[39m# this implementation is a bit faster with smaller shape[1]\u001b[39;00m\n\u001b[0;32m    447\u001b[0m     M \u001b[39m=\u001b[39m M\u001b[39m.\u001b[39mT\n\u001b[1;32m--> 449\u001b[0m Q \u001b[39m=\u001b[39m randomized_range_finder(\n\u001b[0;32m    450\u001b[0m     M,\n\u001b[0;32m    451\u001b[0m     size\u001b[39m=\u001b[39;49mn_random,\n\u001b[0;32m    452\u001b[0m     n_iter\u001b[39m=\u001b[39;49mn_iter,\n\u001b[0;32m    453\u001b[0m     power_iteration_normalizer\u001b[39m=\u001b[39;49mpower_iteration_normalizer,\n\u001b[0;32m    454\u001b[0m     random_state\u001b[39m=\u001b[39;49mrandom_state,\n\u001b[0;32m    455\u001b[0m )\n\u001b[0;32m    457\u001b[0m \u001b[39m# project M to the (k + p) dimensional space using the basis vectors\u001b[39;00m\n\u001b[0;32m    458\u001b[0m B \u001b[39m=\u001b[39m safe_sparse_dot(Q\u001b[39m.\u001b[39mT, M)\n",
      "File \u001b[1;32mc:\\Users\\youngkj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\extmath.py:258\u001b[0m, in \u001b[0;36mrandomized_range_finder\u001b[1;34m(A, size, n_iter, power_iteration_normalizer, random_state)\u001b[0m\n\u001b[0;32m    255\u001b[0m random_state \u001b[39m=\u001b[39m check_random_state(random_state)\n\u001b[0;32m    257\u001b[0m \u001b[39m# Generating normal random vectors with shape: (A.shape[1], size)\u001b[39;00m\n\u001b[1;32m--> 258\u001b[0m Q \u001b[39m=\u001b[39m random_state\u001b[39m.\u001b[39;49mnormal(size\u001b[39m=\u001b[39;49m(A\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m], size))\n\u001b[0;32m    259\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(A, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m A\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    260\u001b[0m     \u001b[39m# Ensure f32 is preserved as f32\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     Q \u001b[39m=\u001b[39m Q\u001b[39m.\u001b[39mastype(A\u001b[39m.\u001b[39mdtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mnumpy\\\\random\\\\mtrand.pyx:1556\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.normal\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_common.pyx:636\u001b[0m, in \u001b[0;36mnumpy.random._common.cont\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 37.8 GiB for an array with shape (71270, 71279) and data type float64"
     ]
    }
   ],
   "source": [
    "svd = TruncatedSVD(n_components=min(X.shape) - 1)  # Set maximum number of components\n",
    "\n",
    "# Fit TruncatedSVD on the sparse matrix\n",
    "svd.fit(X)\n",
    "\n",
    "# Plotting the explained variance ratio\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, svd.n_components + 1), svd.explained_variance_ratio_.cumsum(), marker='o', linestyle='--')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance Ratio')\n",
    "plt.title('Explained Variance Ratio vs. Number of Components')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "78f26278aaebced278c5097c56985d85bde54a4cf6cf6ca5c930d7239c5fca84"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
